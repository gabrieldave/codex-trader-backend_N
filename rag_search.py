"""
游댌 B칔SQUEDA RAG CON FILTROS POR METADATOS
==========================================

Funciones para realizar b칰squedas vectoriales con filtros por metadatos
de documentos (idioma, categor칤a, autor, a침o, etc.)
"""

import os
import sys
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Optional, List, Dict, Any
from urllib.parse import quote_plus
from dotenv import load_dotenv

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

load_dotenv()

def get_env(key):
    value = os.getenv(key, "")
    if not value:
        for env_key in os.environ.keys():
            if env_key.strip().lstrip('\ufeff') == key:
                value = os.environ[env_key]
                break
    return value.strip('"').strip("'").strip()

SUPABASE_URL = get_env("SUPABASE_URL")
SUPABASE_DB_PASSWORD = get_env("SUPABASE_DB_PASSWORD")

if not SUPABASE_URL or not SUPABASE_DB_PASSWORD:
    raise ValueError("Faltan variables de entorno necesarias")

project_ref = SUPABASE_URL.replace("https://", "").replace(".supabase.co", "")
encoded_password = quote_plus(SUPABASE_DB_PASSWORD)
postgres_connection_string = f"postgresql://postgres:{encoded_password}@db.{project_ref}.supabase.co:5432/postgres"

# Importar configuraci칩n
try:
    import config
    collection_name = config.VECTOR_COLLECTION_NAME
except ImportError:
    collection_name = "knowledge"  # Default

# ============================================================================
# FILTROS DE DOCUMENTOS
# ============================================================================

def get_filtered_doc_ids(
    language: Optional[str] = None,
    category: Optional[str] = None,
    author: Optional[str] = None,
    year_min: Optional[int] = None,
    year_max: Optional[int] = None,
    title_contains: Optional[str] = None
) -> List[str]:
    """
    Obtiene los doc_ids de documentos que cumplen con los filtros especificados
    
    Args:
        language: C칩digo de idioma (ej: 'es', 'en')
        category: Categor칤a/tema (ej: 'trading', 'psicolog칤a')
        author: Nombre del autor (b칰squeda parcial, case-insensitive)
        year_min: A침o m칤nimo de publicaci칩n
        year_max: A침o m치ximo de publicaci칩n
        title_contains: Texto que debe contener el t칤tulo (b칰squeda parcial)
        
    Returns:
        Lista de doc_ids que cumplen los filtros
    """
    try:
        conn = psycopg2.connect(postgres_connection_string, connect_timeout=10)
        cur = conn.cursor()
        
        # Construir query con filtros
        query = "SELECT doc_id FROM documents WHERE 1=1"
        params = []
        
        if language:
            query += " AND language = %s"
            params.append(language)
        
        if category:
            query += " AND category = %s"
            params.append(category)
        
        if author:
            query += " AND LOWER(author) LIKE %s"
            params.append(f"%{author.lower()}%")
        
        if year_min:
            query += " AND (published_year IS NULL OR published_year >= %s)"
            params.append(year_min)
        
        if year_max:
            query += " AND (published_year IS NULL OR published_year <= %s)"
            params.append(year_max)
        
        if title_contains:
            query += " AND LOWER(title) LIKE %s"
            params.append(f"%{title_contains.lower()}%")
        
        cur.execute(query, params)
        doc_ids = [row[0] for row in cur.fetchall()]
        
        cur.close()
        conn.close()
        
        return doc_ids
        
    except Exception as e:
        print(f"丘멆잺  Error obteniendo doc_ids filtrados: {e}")
        return []

# ============================================================================
# B칔SQUEDA VECTORIAL CON FILTROS
# ============================================================================

def search_with_filters(
    query: str,
    top_k: int = 10,
    language: Optional[str] = None,
    category: Optional[str] = None,
    author: Optional[str] = None,
    year_min: Optional[int] = None,
    year_max: Optional[int] = None,
    title_contains: Optional[str] = None,
    embedding_model: Optional[Any] = None,
    vector_store: Optional[Any] = None
) -> List[Dict[str, Any]]:
    """
    Realiza una b칰squeda vectorial con filtros por metadatos
    
    Flujo:
    1. Filtrar documentos por metadatos (obtener doc_ids)
    2. Realizar b칰squeda vectorial solo en chunks de esos doc_ids
    3. Devolver resultados con informaci칩n de documentos
    
    Args:
        query: Texto de b칰squeda
        top_k: N칰mero de resultados a devolver
        language: Filtrar por idioma
        category: Filtrar por categor칤a
        author: Filtrar por autor
        year_min: A침o m칤nimo
        year_max: A침o m치ximo
        title_contains: Texto en t칤tulo
        embedding_model: Modelo de embeddings (opcional, se usar치 para generar query embedding)
        vector_store: VectorStore de LlamaIndex (opcional)
        
    Returns:
        Lista de dicts con resultados:
        {
            'chunk_id': str,
            'doc_id': str,
            'content': str,
            'score': float,
            'metadata': dict,
            'document_info': dict  # Info de la tabla documents
        }
    """
    # Paso 1: Obtener doc_ids filtrados
    filtered_doc_ids = get_filtered_doc_ids(
        language=language,
        category=category,
        author=author,
        year_min=year_min,
        year_max=year_max,
        title_contains=title_contains
    )
    
    if not filtered_doc_ids:
        return []  # No hay documentos que cumplan los filtros
    
    # Paso 2: Realizar b칰squeda vectorial en chunks filtrados
    try:
        conn = psycopg2.connect(postgres_connection_string, connect_timeout=10)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # Si tenemos embedding_model, generar embedding de la query
        # Si no, usar b칰squeda por texto (menos preciso pero funcional)
        
        # Por ahora, b칰squeda simple por texto en contenido
        # TODO: Integrar con LlamaIndex VectorStore para b칰squeda vectorial real
        
        # Construir query SQL para buscar en chunks
        doc_ids_placeholders = ','.join(['%s'] * len(filtered_doc_ids))
        
        query_sql = f"""
            SELECT 
                id,
                metadata->>'chunk_id' as chunk_id,
                metadata->>'doc_id' as doc_id,
                metadata->>'file_name' as file_name,
                metadata->>'chunk_index' as chunk_index,
                metadata->>'content' as content,
                metadata->>'book_title' as book_title
            FROM vecs.{collection_name}
            WHERE metadata->>'doc_id' IN ({doc_ids_placeholders})
            AND (
                metadata->>'content' ILIKE %s
                OR metadata->>'book_title' ILIKE %s
            )
            LIMIT %s
        """
        
        params = filtered_doc_ids + [f"%{query}%", f"%{query}%", top_k]
        
        cur.execute(query_sql, params)
        results = cur.fetchall()
        
        # Paso 3: Obtener informaci칩n de documentos
        doc_ids_in_results = list(set([r['doc_id'] for r in results if r['doc_id']]))
        
        documents_info = {}
        if doc_ids_in_results:
            doc_ids_placeholders = ','.join(['%s'] * len(doc_ids_in_results))
            cur.execute(f"""
                SELECT doc_id, filename, title, author, language, category, published_year
                FROM documents
                WHERE doc_id IN ({doc_ids_placeholders})
            """, doc_ids_in_results)
            
            for row in cur.fetchall():
                documents_info[row['doc_id']] = dict(row)
        
        cur.close()
        conn.close()
        
        # Formatear resultados
        formatted_results = []
        for result in results:
            doc_id = result['doc_id']
            formatted_results.append({
                'chunk_id': result.get('chunk_id'),
                'doc_id': doc_id,
                'content': result.get('content') or '',
                'score': 1.0,  # Placeholder, se calcular칤a con similitud vectorial
                'metadata': {
                    'file_name': result.get('file_name'),
                    'chunk_index': result.get('chunk_index'),
                    'book_title': result.get('book_title')
                },
                'document_info': documents_info.get(doc_id, {})
            })
        
        return formatted_results
        
    except Exception as e:
        print(f"丘멆잺  Error en b칰squeda con filtros: {e}")
        return []

# ============================================================================
# FUNCI칍N DE B칔SQUEDA CON LLAMAINDEX (RECOMENDADA)
# ============================================================================

def search_with_filters_llamaindex(
    query: str,
    vector_store: Any,
    embedding_model: Any,
    top_k: int = 10,
    language: Optional[str] = None,
    category: Optional[str] = None,
    author: Optional[str] = None,
    year_min: Optional[int] = None,
    year_max: Optional[int] = None,
    title_contains: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    Realiza b칰squeda vectorial usando LlamaIndex con filtros por metadatos
    
    Esta es la funci칩n recomendada para b칰squedas reales con embeddings.
    
    Args:
        query: Texto de b칰squeda
        vector_store: VectorStore de LlamaIndex (SupabaseVectorStore)
        embedding_model: Modelo de embeddings
        top_k: N칰mero de resultados
        ... (resto de filtros igual que search_with_filters)
        
    Returns:
        Lista de resultados con informaci칩n completa
    """
    # Paso 1: Obtener doc_ids filtrados
    filtered_doc_ids = get_filtered_doc_ids(
        language=language,
        category=category,
        author=author,
        year_min=year_min,
        year_max=year_max,
        title_contains=title_contains
    )
    
    if not filtered_doc_ids:
        return []
    
    # Paso 2: Crear query engine con filtros
    try:
        from llama_index.core import VectorStoreIndex, QueryBundle
        from llama_index.core.schema import NodeWithScore
        
        # Crear 칤ndice desde el vector store
        index = VectorStoreIndex.from_vector_store(vector_store)
        
        # Generar embedding de la query
        query_embedding = embedding_model.get_query_embedding(query)
        
        # Realizar b칰squeda vectorial
        # Nota: Esto es un ejemplo simplificado
        # En producci칩n, usar칤as el retriever de LlamaIndex con filtros de metadata
        
        # Por ahora, usar b칰squeda directa en Supabase con filtros
        # TODO: Integrar completamente con LlamaIndex retriever
        
        return search_with_filters(
            query=query,
            top_k=top_k,
            language=language,
            category=category,
            author=author,
            year_min=year_min,
            year_max=year_max,
            title_contains=title_contains
        )
        
    except Exception as e:
        print(f"丘멆잺  Error en b칰squeda LlamaIndex: {e}")
        return []















